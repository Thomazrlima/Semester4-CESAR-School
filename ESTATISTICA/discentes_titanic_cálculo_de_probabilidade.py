# -*- coding: utf-8 -*-
"""Discentes_Titanic - Cálculo de Probabilidade.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ajuYA8YIXno7usZF8sWhjtA96YXBgaTI

**Estatística e Probabilidade Aplicada**
"""

import pandas as pd #importando as bibliotecas
import numpy as np

from google.colab import drive #importando o drive

drive.mount('/content/gdrive') #autorizando o acesso ao drive e chamando o google drive

from google.colab import files #comando para importar arquivos no colab
uploaded = files.upload() #comando para fazer o upload do arquivo

titanic = pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/titanic.csv')

leitura = pd.read_csv('titanic.csv') #realiza a leitura do arquivo importado
leitura.head(10) #comando head serve para exibir as 5 primeiras linhas do dataframe #SibSp = sibling/spouse (irmão/cônjuge), parch = parent/child, fare = tarifa
#C = Cherbourg, Q = Queenstown, S = Southampton

"""**Probabilidade Simples**

Qual a probabilidade de selecionar uma pessoa e essa pessoa ser mulher?
"""

probMu = len(titanic[titanic['Sex']== 'female']) / len(titanic)
print('A probabilidade de ser mulher no Titanic é igual a: '+ str(round(probMu*100,2)) + '%') #converte a variável proMU em uma string com 4 casas decimais

probH = len(titanic[titanic['Sex']== 'male']) / len(titanic)
print(probH)

"""Comparativos: a população de mulheres em 1912 é correspondente ao do titanic?"""

#referência externa: (https://www.census.gov/data/tables/time-series/demo/popest/pre-1980-national.html)
probMu2 = round(45573000/ 93863000, 4)
print('A probabilidade de ser mulher em 1912 é de: '+ str(round(probMu2*100,6)) + '%')

"""**Probabilidade da União**

Qual a probabilidade de estar acompanhando pelo Parch ou pelo SibSp?
"""

Acomp = len(titanic[(titanic['Parch']>0) | (titanic['SibSp']>0)])
probAcomp = round(Acomp/len(titanic), 4)

print('A probabilidade de estar acompanhado pelo pai ou pelo cônjuge é de : '+ str(round(probAcomp*100,4)) + '%')

"""**Probabilidade da Intersecção**

Qual a probabilidade de ser mulher e estar acompanhada?
"""

MuAcomp = len(titanic[((titanic['Parch']>0) | (titanic['SibSp']>0)) & (titanic['Sex'] =='female')])
probMuAcomp = MuAcomp/len(titanic)
print('A probabilidade de ser mulher e estar acompanhada é de : '+ str(round(probMuAcomp*100, 4)) + '%')

"""**Probabilidade do Complemento**

Qual a probabilidade de ser mulher e não estar acompanhada?
"""

probMuNaoAcomp = probMu - probMuAcomp
print('A probabilidade de ser mulher e não estar acompanhada é de : '+ str(round(probMuNaoAcomp*100, 4)) + '%')

"""**Probabilidade da Diferença**

Qual a probabilidade de ser do conjunto SibSp mas não ser do Parh?

Qual a probabilidade de ser acompanhado pelo cônjuge e não ser acompanhado pelo pai?
"""

'''AcompSibSpNaoParch = len(titanic[titanic['SibSp']>0]) - len(titanic[(titanic['Parch']>0) & (titanic['SibSp']>0)])
probAcompSibSpNaoParch = AcompSibSpNaoParch/len(titanic)

print('A probabilidade de ser SibSp mas não ser Parch é de : '+ str(round(probAcompSibSpNaoParch*100, 4)) + '%')'''

#ou

AcompSibNaoParch = len(titanic[(titanic['Parch']==0) & (titanic['SibSp']>0)])
probAcompSibNaoParch = AcompSibNaoParch/len(titanic)

print('A probabilidade de estar acompanhado SibSp e NÃO Parch é : ' + str(round((probAcompSibNaoParch*100),2))+'%')

"""**Probabilidade** **Condicional**

Qual a probabilidade de estar acompanhada sabendo que é uma mulher?

Segunda pergunta para deixar mais claro: qual a probabilidade de estar acompanhado sabendo que foi retirado uma pessoa do grupo de mulheres?
"""

probCond = probMuAcomp/probMu
print('A probabilidade de estar acompanhada sabendo que é uma mulher é : '+ str(round(probCond*100, 4)) + '%')

"""**Teorema  de Bayes**

Qual a probabilidade de ser mulher tal que esteja acompanhada?
"""

probMutqAcomp = (probCond*probMu)/probAcomp
print('A probabilidade de ser mulher tal que esteja acompanhada é de : '+ str(round(probMutqAcomp*100, 4)) + '%')

"""# **Variáveis** **Aleatórias**"""

titanic['Acompanhado']=titanic['SibSp']+titanic['Parch']

titanic.head(10)

titanic['Acompanhado'].value_counts()

titanic['SibSp'].value_counts()

titanic['Acompanhado'].value_counts(sort=False).sort_index()

"""**Função Probabilidade**"""

fp = titanic['Acompanhado'].value_counts(sort=False).sort_index()/titanic['Acompanhado'].count() #divide o número de pessoas com acompanhantes ou não pelo total de passageiros
print(fp)

"""**Função Repartição (Função Cumulativa)**"""

fp.cumsum() #a função cumsum faz uma soma acumulativa em um eixo

"""**Gráfico Simples**"""

import matplotlib.pyplot as plt #biblioteca que traz diversos gráficos

plt.plot(fp) #comando plot serve para criar gráficos de linhas

grafico = fp.cumsum()

plt.plot(grafico, linestyle='--') #definindo o estilo da linha como tracejada
plt.xlabel('Quantidade de Acompanhantes')
plt.ylabel('Probabilidade')
plt.title('Gráfico Acumulado')

"""**Covariância**"""

titanic[['Acompanhado', 'Survived']].cov()

"""**Correlação**"""

titanic[['Acompanhado', 'Survived']].corr()

"""**Tratamento dos dados**

Exibir algumas informações e iniciar o tratamento com os dados originais
"""

titanic.head()

titanic.info()

#Remover algumas colunas para organizar meu dataset
titanic.drop(['PassengerId','Name','Ticket','Cabin','Acompanhado'], axis=1, inplace=True)

titanic.head()

titanic.describe()

#Importar a lib seaborn para observações estatísticas
import seaborn as sns

sns.heatmap(titanic.isnull(), yticklabels = False)

#Completar os valores null com a mediana das idades por classe.
titanic.loc[titanic.Age.isna() & (titanic.Pclass==1), 'Age'] = titanic[titanic.Pclass==1].Age.median()
titanic.loc[titanic.Age.isna() & (titanic.Pclass==2), 'Age'] = titanic[titanic.Pclass==2].Age.median()
titanic.loc[titanic.Age.isna() & (titanic.Pclass==3), 'Age'] = titanic[titanic.Pclass==3].Age.median()

sns.heatmap(titanic.isnull(), yticklabels = False)

sum(titanic.Embarked.isna())

#Eliminar as faltantes de Emabarked
titanic.dropna(inplace=True)

subset = titanic[['Pclass', 'Survived']] #criando um subconjunto

matriz_rel = subset.corr() #definindo a matriz de correlação

sns.heatmap(matriz_rel, annot = True, cmap = 'coolwarm') #coolwarm é útil para definir cores em mapas de calor (azul e vermelho) #annot serve para fazer dados importantes/informações serem expostas no gráfico
plt.title('Mapa de calor - Classe x Sobreviventes')
plt.show()

titanic.info()

sns.heatmap(titanic.isnull(), yticklabels = False, cbar=False)

from sklearn.preprocessing import LabelEncoder #label encoder é uma técnica para atribuir valor numérico a variáves categóricas
import pandas as pd

# Exemplo de dados categóricos
df = pd.DataFrame({'Embarked': ['C', 'Q', 'S']})

# Inicialize o LabelEncoder
encoder = LabelEncoder()

# Ajuste e transforme os dados
df['Embarked_encoded'] = encoder.fit_transform(df['Embarked'])

print(df)

#Converter os valores literais em numéricos (Embarked)
embark = pd.get_dummies(titanic['Embarked'], drop_first=True)
embark

#Converter os valores literais em numéricos (Sexo)
sexo = pd.get_dummies(titanic['Sex'], drop_first=True)
sexo

from sklearn.preprocessing import LabelEncoder
import pandas as pd

# Exemplo de dados categóricos
df = pd.DataFrame({'Sex': ['male', 'female']})

# Inicialize o LabelEncoder
encoder = LabelEncoder()

# Ajuste e transforme os dados
df['Sex_encoded'] = encoder.fit_transform(df['Sex'])

print(df)

#Concatenar as Colunas no Dataframe
titanic = pd.concat([titanic, embark, sexo], axis=1)

titanic.head()

titanic.drop(['Embarked','Sex'], axis=1, inplace=True)
titanic.head()

titanic.describe()

"""**Distribuição Normal**"""

x = np.arange(-3, 3, 0.001) #a função arange define os limites da variável e o incremento
# Média e desvio padrão
mu = 0
sigma = 1

# Função densidade de probabilidade da distribuição normal
y = (1 / (sigma * np.sqrt(2 * np.pi))) * np.exp(-(x - mu)**2 / (2 * sigma**2))

# Plotando a curva normal
plt.plot(x, y, label="Curva Normal")
plt.xlabel("Valores")
plt.ylabel("Densidade de Probabilidade")
plt.title("Curva da Distribuição Normal")
plt.legend()
plt.show()

#importar a bibliotaca StandardScaler para aplicar a normalização (z=(valor - média)/desvio padão)
#Média = 0 e o Variância = 1

from sklearn.preprocessing import StandardScaler #sklearn.preprocessing fornece várias funções de utilidade comuns e classes de transformadores para alterar vetores de recursos brutos em uma representação mais adequada

scaler = StandardScaler() #o módulo standard.scaler padroniza os dados
ajuste = scaler.fit(titanic) #determina a média e o desvio padrão
normal = scaler.transform(titanic) #aplicar a normal padrão z=(valor - média)/desvio padrão

normalpadrao = pd.DataFrame(normal)
normalpadrao.head()

"""**Distribuição de Probabilidade**"""

house = pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/house.csv')

import scipy #bibloteca para resolução de problemas de matemática e engenharia
import scipy.stats #módulo com grande variadade de funções
size=700000 #tamanho da escala dos eixos coordenados
x = np.arange(size) #a função arange retorna uma matriz de valores igualmente espaçados dentro do intervalo especificado
y = house['SalePrice'].values
h = plt.hist(y, density=True) #chamando a função histograma, o histograma aqui é unidimensional em y e density = True normaliza os dados

dist_names = ['expon', 'logistic', 'norm']
for dist_name in dist_names:  #o comando for _ in cria um laço
  dist = getattr(scipy.stats, dist_name) #a função getattr retorna o valor de um atributo de um objeto
  params = dist.fit(y)
  arg = params[:-2] #cria uma nova lista mostrando os primeiros elementos excluindo os 2 últimos elementos
  loc = params[-2] #localiza o penúltimo elemento
  scale = params[-1] #localiza o último elemento
  if arg:
    pdf_fitted = dist.pdf(x, *arg, loc=loc, scale=scale) #*arg permite que a função aceite números variáveis de argumentos posicionais; loc = loc é a mesma coisa de loc = loc + loc
  else:
    pdf_fitted = dist.pdf(x, loc=loc, scale=scale)
  plt.plot(pdf_fitted, label=dist_name)

plt.legend(loc= 'upper right')

"""**Estatística Descritiva - Gráficos**"""

house.head()

house['SalePrice'].describe()

import plotly.express as px #plotly é uma biblioteca com gráficos exclusivos para visualização de dados
fig = px.histogram(house, x='SalePrice', marginal = 'rug') #função histograma e o comando marginal cria histogramas marginais e ocomando rug cria "marcas"
fig.show()

fig2 = px.box(house, x='GarageCars', y='SalePrice') #cria o box plot e personaliza os eixos coordenados
fig2.show()

import seaborn as sns
col = ['SalePrice', 'OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt']
sns.pairplot(house[col]) #cria pares de gráficos

house[['SalePrice', 'GrLivArea']].corr()

"""**Distribuição Amostral**"""

#importar as libs para trabalhar com números aleatórios
from numpy.random import seed #inicializar o gerador de números aleatórios
from numpy.random import randint #retorna um número inteiro aleatório
from numpy import mean

seed(1)

rols = randint(1,7,50)
print(rols)
print(mean(rols))

from matplotlib import pyplot

means=[mean(randint(1,7,1)) for _ in range(1000)] #comando que cria um loop sobre uma sequência de elementos

pyplot.hist(means)
pyplot.show()

means=[mean(randint(1,7,2)) for _ in range(1000)]

pyplot.hist(means)
pyplot.show()

means=[mean(randint(1,7,10)) for _ in range(1000)]

pyplot.hist(means)
pyplot.show()

means=[mean(randint(1,7,50)) for _ in range(1000)]

pyplot.hist(means)
pyplot.show()

means=[mean(randint(1,7,100)) for _ in range(1000)]

pyplot.hist(means)
pyplot.show()

"""Intervalo de Confiança"""

from scipy.stats import norm

house = df['LotFrontage'] #antes devem ser definidos quem é o df

media = house.mean()
desvio_padrao = house.std()
num = len(house)

erro_padrao = desvio_padrao / np.sqrt(num)

z_valor = norm.ppf(0.95) #comando ppf encotra o valor solicitado
margem_erro = erro_padrao * z_valor

limite_inferior = media - margem_erro
limite_superior = media + margem_erro

x_valores = np.linspace(media - 3*desvio_padrao, media + 3*desvio_padrao, 1000)
y_valores = norm.pdf(x_valores, media, desvio_padrao)

plt.figure(figsize=(10, 5))
plt.plot(x_valores, y_valores, label='Distribuição Normal')


plt.axvline(x=limite_inferior, color='grey', linestyle='--', label=f'Limite Inferior = {limite_inferior:.2f}') #comando que adiciona linhas verticais: axvline
plt.axvline(x=limite_superior, color='grey', linestyle='--', label=f'Limite Superior = {limite_superior:.2f}')


plt.title('Distribuição Normal do Limite Total com Intervalo de Confiança de 95%')
plt.xlabel('LotFrontage')
plt.ylabel('Densidade de Probabilidade')

plt.show()